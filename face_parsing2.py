# -*- coding: utf-8 -*-
"""face_parsing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12451YRgNKa6AgIfxn0yz3htbkdsynKzB
"""

import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import cv2

pip install git+https://github.com/FacePerceiver/facer.git@main

from google.colab import files

# íŒŒì¼ ì—…ë¡œë“œ
uploaded = files.upload()

import torch
import facer
import numpy as np
import matplotlib.pyplot as plt

# 1. ì´ë¯¸ì§€ ë¡œë“œ ë° face parsing
device = 'cuda' if torch.cuda.is_available() else 'cpu'
image = facer.hwc2bchw(facer.read_hwc('/content/woojin.png')).to(device)

face_detector = facer.face_detector('retinaface/mobilenet', device=device)
with torch.inference_mode():
    faces = face_detector(image)

face_parser = facer.face_parser('farl/lapa/448', device=device)
with torch.inference_mode():
    faces = face_parser(image, faces)

# 2. ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼
seg_logits = faces['seg']['logits']
seg_probs = seg_logits.softmax(dim=1)
parsed_classes = seg_probs.argmax(dim=1)

# 3. ì¶”ì¶œí•˜ê³  ì‹¶ì€ ë¶€ìœ„ ë¦¬ìŠ¤íŠ¸ (ì¢Œìš° í†µí•© í¬í•¨)
merged_labels = {
    'face_skin': [1],
    'eyebrows': [2, 3],
    'eyes': [4, 5],
    'nose': [6],
    'lips': [7, 9],
    'inner_mouth': [8],
    'hair': [10]
}

# 4. ë¶€ìœ„ë³„ ì¶”ì¶œ
extracted_parts = {}

for part_name, class_indices in merged_labels.items():
    mask = torch.zeros_like(parsed_classes, dtype=torch.bool)
    for idx in class_indices:
        mask |= (parsed_classes == idx)
    part_image = image * mask.unsqueeze(1).float()  # [B, C, H, W]
    extracted_parts[part_name] = part_image

plt.figure(figsize=(16, 10))
for i, (part_name, part_img) in enumerate(extracted_parts.items()):
    plt.subplot(2, 4, i + 1)
    facer.show_bchw(part_img)
    plt.title(part_name)
plt.tight_layout()
plt.show()
## ì—¬ê¸°ê¹Œì§€ ë¶€ìœ„ ì¶”ì¶œ ê´€ë ¨ ì½”ë“œ - ê·¸ ë‹¤ìŒë¶€í„°ëŠ” ìƒ‰ ì¶”ì¶œ

print(image.shape)

# ì›ë³¸ì´ë¯¸ì§€ [1, 3, H, W] â†’ NumPy [H, W, 3] - ì›ë³¸ì´ë¯¸ì§€ë¥¼ NumPyì—ì„œ ì“°ê¸° ìœ„í•´ì„œ ë³€í™˜í•˜ëŠ”ê³¼ì •.
image_np = image[0].permute(1, 2, 0).cpu().numpy()  # shape: (506, 524, 3)

plt.imshow(image_np)

# 1. í”¼ë¶€ ë¶€ìœ„ ë§ˆìŠ¤í¬ ìƒì„± (í´ë˜ìŠ¤ ë²ˆí˜¸ 1 = face_skin) - True / False ë¡œ êµ¬ë¶„ëœ ì´ë¯¸ì§€ - í”¼ë¶€ë¶€ìœ„ ë§ˆìŠ¤í¬ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œ
skin_mask_tensor = (parsed_classes == 1)
skin_mask = skin_mask_tensor.squeeze().cpu().numpy().astype(bool)  # shape: (H, W)
plt.imshow(skin_mask)

skin_pixels = image_np[skin_mask]


# ë§ˆìŠ¤í¬ì—ì„œ í”¼ë¶€ë¼ê³  ì¸ì‹í•œ ì´ë¯¸ì§€ì— í•´ë‹¹í•˜ëŠ” í”½ì…€ì˜ ê°’ì˜ í‰ê· ì„ êµ¬í•œë‹¤.
if skin_pixels.shape[0] == 0:
    print("â—ï¸ë§ˆìŠ¤í¬ì— í•´ë‹¹í•˜ëŠ” í”½ì…€ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    mean_rgb = np.mean(skin_pixels, axis=0)
    print(f"ğŸ“Š í‰ê·  RGB ê°’: R={mean_rgb[0]:.1f}, G={mean_rgb[1]:.1f}, B={mean_rgb[2]:.1f}")