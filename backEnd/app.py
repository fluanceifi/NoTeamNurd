from flask import Flask, request, jsonify
from flask_cors import CORS
import os
from dotenv import load_dotenv
import base64
from PIL import Image, ImageEnhance, ImageFilter
import cv2
import numpy as np
from rembg import remove
import torch
import facer
import numpy as np
import matplotlib.pyplot as plt
from scipy import ndimage
from flask_mail import Mail, Message
from gradio_client import Client, file
import shutil

latest_paths = []
outfit_preview_paths = {}  # {'original': 'path1', 'formal': 'path2', 'casual': 'path3'}
final_image_path = None
selected_gender = None
latest_color_category = None

def create_id_photo(image_path: str, target_ratio=(3, 4)) -> str:
    """
    Create an ID photo by detecting face and cropping to include face and some shoulders
    """
    # Load the image
    img = cv2.imread(image_path)
    if img is None:
        raise Exception("Failed to load image")

    # Convert to RGB for face detection (OpenCV uses BGR by default)
    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Load the face detection model
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

    # Detect faces
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.1, 4)

    if len(faces) == 0:
        print("No face detected, using default resizing")
        # Fall back to your original resize function if no face is detected
        pil_img = Image.open(image_path)
        width, height = pil_img.size
        target_width = width
        target_height = int(width * target_ratio[1] / target_ratio[0])

        if target_height > height:
            padding = (target_height - height) // 2
            new_image = Image.new("RGB", (width, target_height), (255, 255, 255))
            new_image.paste(pil_img, (0, padding))
        else:
            top = (height - target_height) // 2
            new_image = pil_img.crop((0, top, width, top + target_height))
    else:
        # Get the largest face (in case multiple faces are detected)
        (x, y, w, h) = max(faces, key=lambda f: f[2] * f[3])

        # Calculate the ID photo crop dimensions
        img_height, img_width = img.shape[:2]

        # Face center
        face_center_x = x + w // 2
        face_center_y = y + h // 2

        # ì¦ëª…ì‚¬ì§„ ìŠ¤íƒ€ì¼ì— ë§ê²Œ ì–¼êµ´ ë¹„ìœ¨ ì¡°ì •
        # ì–¼êµ´ì´ ì´ë¯¸ì§€ì—ì„œ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨ (ì„¸ ë²ˆì§¸ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼)
        face_scale = 0.4  # ì–¼êµ´ì´ ì „ì²´ ë†’ì´ì˜ 40% ì •ë„ ì°¨ì§€í•˜ë„ë¡ ì„¤ì •

        # Calculate new height based on face height
        new_height = int(h / face_scale)

        # Calculate new width based on target aspect ratio
        new_width = int(new_height * target_ratio[0] / target_ratio[1])

        # ì–¼êµ´ ìœ„ì¹˜ ì¡°ì • - ìƒë‹¨ì— ë” ë§ì€ ì—¬ë°±ì„ ì£¼ê¸° ìœ„í•´ ìœ„ì¹˜ë¥¼ ì•„ë˜ë¡œ ì¡°ì •
        # ì„¸ ë²ˆì§¸ ì´ë¯¸ì§€ì²˜ëŸ¼ ì–¼êµ´ì´ ì¤‘ì•™ë³´ë‹¤ ì•½ê°„ ìœ„ìª½ì— ìœ„ì¹˜í•˜ë„ë¡ ì„¤ì •
        face_top_position = 0.38  # ì–¼êµ´ ìƒë‹¨ì´ ì´ë¯¸ì§€ ìƒë‹¨ì—ì„œ 38% ìœ„ì¹˜ì— ì˜¤ë„ë¡ ì¡°ì •

        # Calculate top-left corner of crop area
        crop_x = max(0, face_center_x - new_width // 2)
        crop_y = max(0, face_center_y - int(face_top_position * new_height))

        # ìœ„ìª½ì´ ì˜ë¦¬ì§€ ì•Šë„ë¡ ì¶”ê°€ ì¡°ì •
        if crop_y < 0:
            # ìƒë‹¨ ì—¬ë°±ì´ ë¶€ì¡±í•˜ë©´ í•˜ë‹¨ì„ ë” í¬í•¨
            crop_y = 0

        # Adjust if crop area goes beyond image boundaries
        if crop_x + new_width > img_width:
            crop_x = img_width - new_width
        if crop_y + new_height > img_height:
            crop_y = img_height - new_height

        # Ensure crop coordinates are non-negative
        crop_x = max(0, crop_x)
        crop_y = max(0, crop_y)

        # Crop the image
        cropped = img[crop_y:crop_y + new_height, crop_x:crop_x + new_width]

        # Convert back to PIL for saving
        new_image = Image.fromarray(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))

    # ê²°ê³¼ ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • ëŒ€ì‹  ë¹„ìœ¨ë§Œ ìœ ì§€
    output_path = image_path.replace('.jpg', '_idphoto.jpg')
    new_image.save(output_path)
    return output_path


def apply_natural_enhancement(image: Image.Image, enhancement_level: str = "medium") -> Image.Image:
    """
    ìì—°ìŠ¤ëŸ¬ìš´ ë½€ìƒµ íš¨ê³¼ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
    enhancement_level: "light", "medium", "strong"
    """

    # ê°•ë„ ì„¤ì •
    enhancement_settings = {
        "light": {
            "brightness": 1.05,
            "contrast": 1.03,
            "color": 1.02,
            "sharpness": 1.02,
            "smooth_strength": 0.3
        },
        "medium": {
            "brightness": 1.08,
            "contrast": 1.05,
            "color": 1.05,
            "sharpness": 1.05,
            "smooth_strength": 0.5
        },
        "strong": {
            "brightness": 1.12,
            "contrast": 1.08,
            "color": 1.08,
            "sharpness": 1.08,
            "smooth_strength": 0.7
        }
    }

    settings = enhancement_settings.get(enhancement_level, enhancement_settings["medium"])

    # PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜
    img_array = np.array(image)

    # 1. í”¼ë¶€ ìŠ¤ë¬´ë”© (ìì—°ìŠ¤ëŸ¬ìš´ ë¸”ëŸ¬ íš¨ê³¼)
    # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë¶€ë“œëŸ½ê²Œ ë§Œë“¤ê¸°
    blurred = cv2.GaussianBlur(img_array, (15, 15), 0)

    # ì›ë³¸ê³¼ ë¸”ëŸ¬ëœ ì´ë¯¸ì§€ë¥¼ ì ì ˆíˆ í˜¼í•©
    smooth_strength = settings["smooth_strength"]
    smoothed = cv2.addWeighted(img_array, 1 - smooth_strength, blurred, smooth_strength, 0)

    # numpy arrayë¥¼ ë‹¤ì‹œ PIL Imageë¡œ ë³€í™˜
    enhanced_image = Image.fromarray(smoothed.astype(np.uint8))

    # 2. ë°ê¸° ì¡°ì • (ìì—°ìŠ¤ëŸ½ê²Œ ë°ê²Œ)
    brightness_enhancer = ImageEnhance.Brightness(enhanced_image)
    enhanced_image = brightness_enhancer.enhance(settings["brightness"])

    # 3. ëŒ€ë¹„ ì¡°ì • (ì„ ëª…í•˜ê²Œ)
    contrast_enhancer = ImageEnhance.Contrast(enhanced_image)
    enhanced_image = contrast_enhancer.enhance(settings["contrast"])

    # 4. ìƒ‰ìƒ ì±„ë„ ì¡°ì • (ìƒê¸°ìˆê²Œ)
    color_enhancer = ImageEnhance.Color(enhanced_image)
    enhanced_image = color_enhancer.enhance(settings["color"])

    # 5. ì„ ëª…ë„ ì¡°ì • (ìì—°ìŠ¤ëŸ½ê²Œ ë˜ë ·í•˜ê²Œ)
    sharpness_enhancer = ImageEnhance.Sharpness(enhanced_image)
    enhanced_image = sharpness_enhancer.enhance(settings["sharpness"])

    return enhanced_image


def detect_face_region(image_path: str) -> tuple:
    """
    ì–¼êµ´ ì˜ì—­ì„ ê°ì§€í•˜ì—¬ ì¢Œí‘œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    img = cv2.imread(image_path)
    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.1, 4)

    if len(faces) > 0:
        return max(faces, key=lambda f: f[2] * f[3])  # ê°€ì¥ í° ì–¼êµ´ ë°˜í™˜
    return None


def apply_selective_enhancement(image: Image.Image, face_coords: tuple = None,
                                enhancement_level: str = "medium") -> Image.Image:
    """
    ì–¼êµ´ ì˜ì—­ì—ë§Œ ì§‘ì¤‘ì ìœ¼ë¡œ ë½€ìƒµì„ ì ìš©í•©ë‹ˆë‹¤.
    """
    if face_coords is None:
        return apply_natural_enhancement(image, enhancement_level)

    x, y, w, h = face_coords
    img_array = np.array(image)

    # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
    face_region = img_array[y:y + h, x:x + w]
    face_img = Image.fromarray(face_region)

    # ì–¼êµ´ ì˜ì—­ì—ë§Œ ê°•í™” íš¨ê³¼ ì ìš©
    enhanced_face = apply_natural_enhancement(face_img, enhancement_level)
    enhanced_face_array = np.array(enhanced_face)

    # ì›ë³¸ ì´ë¯¸ì§€ì— enhanced ì–¼êµ´ ì˜ì—­ì„ ë‹¤ì‹œ í•©ì„±
    result_array = img_array.copy()
    result_array[y:y + h, x:x + w] = enhanced_face_array

    return Image.fromarray(result_array)


def remove_background_rembg(image_path: str) -> Image.Image:
    """
    rembg ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°ê²½ì„ ì œê±°í•©ë‹ˆë‹¤.
    """
    from rembg import remove
    input_image = Image.open(image_path)
    output_image = remove(input_image)
    return output_image


def analyze_face(image_path):
    # 1. ì´ë¯¸ì§€ ë¡œë“œ
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    image = facer.hwc2bchw(facer.read_hwc(image_path)).to(device)

    # 2. Face Parsing
    face_detector = facer.face_detector('retinaface/mobilenet', device=device)
    with torch.inference_mode():
        faces = face_detector(image)

    face_parser = facer.face_parser('farl/lapa/448', device=device)
    with torch.inference_mode():
        faces = face_parser(image, faces)

    # 3. í”¼ë¶€ ì˜ì—­ ë§ˆìŠ¤í¬ ìƒì„±
    seg_logits = faces['seg']['logits']
    seg_probs = seg_logits.softmax(dim=1)
    parsed_classes = seg_probs.argmax(dim=1)

    skin_mask = (parsed_classes[0] == 1).squeeze(0).squeeze(0).cpu().numpy().astype(bool)

    # ğŸ›  ë§ˆìŠ¤í¬ê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
    print(f"ğŸ” í”¼ë¶€ ì˜ì—­ í”½ì…€ ê°œìˆ˜: {skin_mask.sum()}")
    if skin_mask.sum() == 0:
        print("â— í”¼ë¶€ ì˜ì—­ì´ ê²€ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    # 4. RGB ìƒ‰ìƒ ë¶„ì„
    image_np = image[0].permute(1, 2, 0).cpu().numpy()
    skin_pixels = image_np[skin_mask]  # í”¼ë¶€ ì˜ì—­ í”½ì…€ ì¶”ì¶œ

    mean_rgb = np.mean(skin_pixels, axis=0) if skin_pixels.shape[0] > 0 else [0, 0, 0]
    print(f"ğŸ“Š í‰ê·  RGB ê°’: R={mean_rgb[0]:.1f}, G={mean_rgb[1]:.1f}, B={mean_rgb[2]:.1f}")

    # 5. HSV ë³€í™˜
    skin_pixels = skin_pixels.astype(np.float32) / 255.0  # 0~1 ì •ê·œí™”
    r, g, b = skin_pixels[:, 0], skin_pixels[:, 1], skin_pixels[:, 2]

    cmax = np.max(skin_pixels, axis=1)
    cmin = np.min(skin_pixels, axis=1)
    delta = cmax - cmin

    # H ê³„ì‚° (íšŒìƒ‰ ê³„ì—´ ë°©ì§€)
    h = np.zeros_like(cmax)
    mask = delta != 0

    r_eq = (cmax == r) & mask
    g_eq = (cmax == g) & mask
    b_eq = (cmax == b) & mask

    h[r_eq] = (60 * ((g[r_eq] - b[r_eq]) / delta[r_eq])) % 360
    h[g_eq] = (60 * ((b[g_eq] - r[g_eq]) / delta[g_eq]) + 120) % 360
    h[b_eq] = (60 * ((r[b_eq] - g[b_eq]) / delta[b_eq]) + 240) % 360

    h[~mask] = 0  # íšŒìƒ‰ ê³„ì—´ (delta == 0)ì¼ ê²½ìš° H = 0

    # S ê³„ì‚°
    s = np.zeros_like(cmax)
    s[cmax != 0] = delta[cmax != 0] / cmax[cmax != 0]

    # V ê³„ì‚°
    v = cmax

    # í‰ê·  HSV ê³„ì‚°
    mean_h = np.mean(h) if h.size > 0 else 0
    mean_s = np.mean(s) * 100 if s.size > 0 else 0
    mean_v = np.mean(v) * 100 if v.size > 0 else 0

    print(f"ğŸ“Š í‰ê·  HSV ê°’: H={mean_h:.1f}, S={mean_s:.1f}, V={mean_v:.1f}")

    return {
        'h': float(round(mean_h, 1)),
        's': float(round(mean_s, 1)),
        'v': float(round(mean_v, 1))
    }


def get_recommended_backgrounds(hsv_data: dict) -> list:
    global latest_color_category

    h, s, v = hsv_data['h'], hsv_data['s'] / 100, hsv_data['v'] / 100
    print(f"ğŸ”¥ ë¶„ì„ëœ HSV ê°’: H={h:.1f}, S={s:.2f}, V={v:.2f}")

    # ê°œì„ ëœ í†¤ í…Œì´ë¸” - ë” ë„“ì€ ë²”ìœ„ë¡œ ìˆ˜ì •
    tone_table = [
        # (í†¤ ì´ë¦„, ê³„ì ˆ ì¹´í…Œê³ ë¦¬, H ë²”ìœ„, S ë²”ìœ„, V ë²”ìœ„)

        # ğŸŒ¸ ë´„ (ë”°ëœ»í•˜ê³  ë°ìŒ) - H: 0-90ë„ (ë”°ëœ»í•œ ìƒ‰ì¡°)
        # íŠ¹ì§•: High V (ë°ìŒ)
        ('ë´„ ë¼ì´íŠ¸', 'ë´„', (0, 70), (0.1, 0.5), (0.75, 1.0)),  # ì €ì±„ë„, ê³ ëª…ë„
        ('ë´„ ë¸Œë¼ì´íŠ¸', 'ë´„', (0, 80), (0.6, 1.0), (0.7, 1.0)),  # ê³ ì±„ë„, ê³ ëª…ë„
        ('ë´„ ì›œ', 'ë´„', (0, 70), (0.3, 0.8), (0.6, 0.95)),  # (True) ì¤‘~ê³ ì±„ë„, ì¤‘~ê³ ëª…ë„

        # ğŸŒŠ ì—¬ë¦„ (ì°¨ê°‘ê³  ë¶€ë“œëŸ¬ì›€) - H: 180-300ë„ (ì°¨ê°€ìš´ ìƒ‰ì¡°)
        # íŠ¹ì§•: Low S (ë¶€ë“œëŸ¬ì›€)
        ('ì—¬ë¦„ ë¼ì´íŠ¸', 'ì—¬ë¦„', (180, 300), (0.05, 0.35), (0.75, 1.0)),  # ì €ì±„ë„, ê³ ëª…ë„
        ('ì—¬ë¦„ ë®¤íŠ¸', 'ì—¬ë¦„', (160, 280), (0.1, 0.4), (0.4, 0.8)),  # ì €ì±„ë„, ì¤‘ëª…ë„
        ('ì—¬ë¦„ ì¿¨', 'ì—¬ë¦„', (170, 320), (0.15, 0.5), (0.5, 0.9)),  # (True) ì €~ì¤‘ì±„ë„, ì¤‘~ê³ ëª…ë„

        # ğŸ‚ ê°€ì„ (ë”°ëœ»í•˜ê³  ê¹Šì´ê° ìˆìŒ) - H: 10-80ë„, ë‚®ì€ ëª…ë„
        # íŠ¹ì§•: Low V (ì–´ë‘ì›€)
        ('ê°€ì„ ë®¤íŠ¸', 'ê°€ì„', (10, 80), (0.1, 0.45), (0.3, 0.7)),  # ì €ì±„ë„, ì €~ì¤‘ëª…ë„
        ('ê°€ì„ ì›œ', 'ê°€ì„', (0, 60), (0.4, 0.9), (0.3, 0.75)),  # (True) ì¤‘~ê³ ì±„ë„, ì €~ì¤‘ëª…ë„
        ('ê°€ì„ ë‹¤í¬', 'ê°€ì„', (5, 50), (0.3, 0.9), (0.15, 0.55)),  # ì¤‘~ê³ ì±„ë„, ì €ëª…ë„

        # â„ï¸ ê²¨ìš¸ (ì°¨ê°‘ê³  ë˜ë ·í•¨) - H: 240-360ë„ (ì¿¨í†¤) + 0-15 (ì¿¨í†¤ ë ˆë“œ)
        # íŠ¹ì§•: High S (ì„ ëª…í•¨) / High Contrast (ê³ ëŒ€ë¹„)
        # (ì°¸ê³ : ê²¨ìš¸ í†¤ì€ 330-360, 0-15 ë²”ìœ„ì˜ 'ì¿¨í†¤ ë ˆë“œ/í•‘í¬'ë¥¼ í¬í•¨í•˜ëŠ” ê²ƒì´ ì •í™•í•©ë‹ˆë‹¤)
        ('ê²¨ìš¸ ë¸Œë¼ì´íŠ¸', 'ê²¨ìš¸', [(0, 15), (310, 360)], (0.7, 1.0), (0.7, 1.0)),  # ê³ ì±„ë„, ê³ ëª…ë„
        ('ê²¨ìš¸ ë”¥', 'ê²¨ìš¸', [(0, 20), (220, 340)], (0.5, 1.0), (0.2, 0.6)),  # ê³ ì±„ë„, ì €ëª…ë„
        ('ê²¨ìš¸ ì¿¨', 'ê²¨ìš¸', [(0, 15), (180, 320)], (0.6, 1.0), (0.45, 0.9)),  # (True) ê³ ì±„ë„, ì¤‘ëª…ë„

        # ğŸŒŸ ë‰´íŠ¸ëŸ´ (ì¤‘ì„±ì ) - ë‚®ì€ ì±„ë„ì˜ ëª¨ë“  ìƒ‰ì¡°
        ('ë‰´íŠ¸ëŸ´ ë¼ì´íŠ¸', 'ë‰´íŠ¸ëŸ´', (0, 360), (0.0, 0.15), (0.7, 1.0)),  # ë§¤ìš° ì—°í•œ ì¤‘ì„± í†¤ (ê³ ëª…ë„)
        ('ë‰´íŠ¸ëŸ´ ë¯¸ë””ì—„', 'ë‰´íŠ¸ëŸ´', (0, 360), (0.0, 0.2), (0.4, 0.7)),  # ì¤‘ê°„ ì¤‘ì„± í†¤ (ì¤‘ëª…ë„)
    ]

    # ê³„ì ˆ ë§¤í•‘ (3ê°€ì§€ ì¶”ì²œìƒ‰ ê°ê° RGBê°’) - ë” ìì—°ìŠ¤ëŸ¬ìš´ ìƒ‰ìƒìœ¼ë¡œ ìˆ˜ì •
    tone_palette = {
        'ë´„': [(255, 248, 220), (255, 235, 205), (248, 225, 190)],  # ë”°ëœ»í•œ ì•„ì´ë³´ë¦¬, í”¼ì¹˜, ë² ì´ì§€
        'ì—¬ë¦„': [(240, 248, 255), (225, 240, 255), (210, 230, 250)],  # ì‹œì›í•œ ë¸”ë£¨ í™”ì´íŠ¸
        'ê°€ì„': [(255, 228, 196), (222, 184, 135), (205, 160, 120)],  # ë”°ëœ»í•œ ë² ì´ì§€, ì¹´í‚¤
        'ê²¨ìš¸': [(248, 248, 255), (230, 230, 250), (220, 220, 240)],  # ì°¨ê°€ìš´ í™”ì´íŠ¸, ë¼ë²¤ë”
        'ë‰´íŠ¸ëŸ´': [(245, 245, 245), (235, 235, 235), (225, 225, 225)]  # ì¤‘ì„± ê·¸ë ˆì´ í†¤
    }

    # ê³„ì ˆ ì¹´í…Œê³ ë¦¬ íŒë‹¨ - ìˆœì„œ ì¤‘ìš” (ë” êµ¬ì²´ì ì¸ ì¡°ê±´ë¶€í„°)
    best_match = None
    best_score = -1

    for tone_name, category, hr, sr, vr in tone_table:
        # ê° ì¡°ê±´ì— ëŒ€í•œ ì ìˆ˜ ê³„ì‚°
        h_match = hr[0] <= h <= hr[1] or (hr[0] > hr[1] and (h >= hr[0] or h <= hr[1]))  # 360ë„ ìˆœí™˜ ê³ ë ¤
        s_match = sr[0] <= s <= sr[1]
        v_match = vr[0] <= v <= vr[1]

        # ë§¤ì¹˜ë˜ëŠ” ì¡°ê±´ì˜ ê°œìˆ˜ë¡œ ì ìˆ˜ ê³„ì‚°
        score = sum([h_match, s_match, v_match])

        # ì™„ì „ ë§¤ì¹˜ ìš°ì„ 
        if score == 3:
            latest_color_category = tone_name
            print(f"âœ… ì™„ì „ ë§¤ì¹˜: {tone_name} (ì¹´í…Œê³ ë¦¬: {category})")
            return tone_palette[category]

        # ë¶€ë¶„ ë§¤ì¹˜ ì¤‘ ìµœê³  ì ìˆ˜ ê¸°ë¡
        if score > best_score:
            best_score = score
            best_match = (tone_name, category)

    # ë¶€ë¶„ ë§¤ì¹˜ë¼ë„ ìˆìœ¼ë©´ ì‚¬ìš©
    if best_match and best_score >= 2:  # 3ê°œ ì¤‘ 2ê°œ ì´ìƒ ë§¤ì¹˜
        latest_color_category = best_match[0]
        print(f"ğŸ” ë¶€ë¶„ ë§¤ì¹˜: {best_match[0]} (ì ìˆ˜: {best_score}/3)")
        return tone_palette[best_match[1]]

    # ì—¬ì „íˆ ë§¤ì¹˜ê°€ ì•ˆ ë˜ë©´ HSV ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ë¡ 
    print(f"âš ï¸ ì§ì ‘ ë§¤ì¹˜ ì‹¤íŒ¨, HSV ê¸°ë°˜ ì¶”ë¡  ì‹œì‘...")

    # H(ìƒ‰ì¡°) ê¸°ë°˜ 1ì°¨ ë¶„ë¥˜
    if 0 <= h <= 90:  # ë”°ëœ»í•œ ìƒ‰ì¡° (ë¹¨ê°•~ë…¸ë‘)
        if v >= 0.65:  # ë°ì€ í¸
            if s <= 0.3:  # ì±„ë„ ë‚®ìŒ
                category = 'ë‰´íŠ¸ëŸ´'
                latest_color_category = 'ë‰´íŠ¸ëŸ´ ë¼ì´íŠ¸'
            else:  # ì±„ë„ ë†’ìŒ
                category = 'ë´„'
                latest_color_category = 'ë´„ ë¼ì´íŠ¸'
        else:  # ì–´ë‘ìš´ í¸
            category = 'ê°€ì„'
            latest_color_category = 'ê°€ì„ ë®¤íŠ¸'
    elif 180 <= h <= 300:  # ì°¨ê°€ìš´ ìƒ‰ì¡° (íŒŒë‘~ë³´ë¼)
        if v >= 0.6:  # ë°ì€ í¸
            category = 'ì—¬ë¦„'
            latest_color_category = 'ì—¬ë¦„ ë¼ì´íŠ¸'
        else:  # ì–´ë‘ìš´ í¸
            category = 'ê²¨ìš¸'
            latest_color_category = 'ê²¨ìš¸ ë”¥'
    else:  # ì¤‘ê°„ ìƒ‰ì¡° ë˜ëŠ” íŠ¹ìˆ˜í•œ ê²½ìš°
        if s <= 0.2:  # ë§¤ìš° ë‚®ì€ ì±„ë„
            category = 'ë‰´íŠ¸ëŸ´'
            latest_color_category = 'ë‰´íŠ¸ëŸ´ ë¯¸ë””ì—„'
        elif v >= 0.7:  # ë§¤ìš° ë°ìŒ
            category = 'ì—¬ë¦„'
            latest_color_category = 'ì—¬ë¦„ ë¼ì´íŠ¸'
        else:
            category = 'ê°€ì„'
            latest_color_category = 'ê°€ì„ ë®¤íŠ¸'

    print(f" ì¶”ë¡  ê²°ê³¼: {latest_color_category} (ì¹´í…Œê³ ë¦¬: {category})")
    return tone_palette[category]


def apply_recommended_backgrounds(foreground_img: Image.Image, base_path: str, rgb_list: list,
                                  enhancement_level: str = "light") -> list:  # ê¸°ë³¸ê°’ë„ "light"ë¡œ ë°”ê¿ˆ
    paths = []

    for idx, rgb in enumerate(rgb_list):
        # ë°°ê²½ ì ìš©
        bg = Image.new("RGBA", foreground_img.size, rgb + (255,))
        bg.paste(foreground_img, (0, 0), foreground_img)
        bg = bg.convert("RGB")

        #  í•­ìƒ light ë³´ì •ìœ¼ë¡œ ê³ ì •
        enhanced_bg = apply_natural_enhancement(bg, enhancement_level)

        path = base_path.replace('.jpg', f'_reco{idx + 1}_{enhancement_level}.jpg')
        enhanced_bg.save(path)
        paths.append(path)

    return paths



def generate_recommended_images(image_path: str) -> list:
    """
    ë°°ê²½ ì œê±°, í¼ìŠ¤ë„ ì»¬ëŸ¬ ë¶„ì„, ë½€ìƒµ íš¨ê³¼ê°€ ì ìš©ëœ ì´ë¯¸ì§€ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    foreground = remove_background_rembg(image_path)  # ë°°ê²½ ì œê±°ëœ ì¸ë¬¼ ì´ë¯¸ì§€
    hsv_data = analyze_face(image_path)  # í”¼ë¶€ HSV ë¶„ì„
    if hsv_data is None:
        raise Exception("HSV ë¶„ì„ ì‹¤íŒ¨")

    palette = get_recommended_backgrounds(hsv_data)  # í¼ìŠ¤ë„ì»¬ëŸ¬ ì¶”ì²œ ë°°ê²½ 3ê°€ì§€
    return apply_recommended_backgrounds(foreground, image_path, palette)


def setup_outfit_assets():
    """
    ì„±ë³„ë³„ ì˜· ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    """
    # ì„±ë³„ë³„ ë””ë ‰í† ë¦¬ ìƒì„±
    male_dir = 'assets/male'
    female_dir = 'assets/female'

    os.makedirs(male_dir, exist_ok=True)
    os.makedirs(female_dir, exist_ok=True)

    # ì„±ë³„ë³„ í•„ìš” íŒŒì¼ ëª©ë¡
    required_files = {
        'male': [
            'assets/male/formal_suit.jpg',  # ë‚¨ì„± ì •ì¥
            'assets/male/casual_shirt.jpg'  # ë‚¨ì„± ìºì£¼ì–¼
        ],
        'female': [
            'assets/female/formal_dress.jpg',  # ì—¬ì„± ì •ì¥/ë“œë ˆìŠ¤
            'assets/female/casual_blouse.jpg'  # ì—¬ì„± ìºì£¼ì–¼
        ]
    }

    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    missing_files = []
    for gender, files in required_files.items():
        for file_path in files:
            if not os.path.exists(file_path):
                missing_files.append(file_path)
                print(f"âš ï¸  í•„ìš”í•œ {gender} ì˜· ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {file_path}")

    if missing_files:
        print("\nğŸ“ ë‹¤ìŒ êµ¬ì¡°ë¡œ ì˜· ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•´ì£¼ì„¸ìš”:")
        print("assets/")
        print("â”œâ”€â”€ male/")
        print("â”‚   â”œâ”€â”€ formal_suit.jpg")
        print("â”‚   â””â”€â”€ casual_shirt.jpg")
        print("â””â”€â”€ female/")
        print("    â”œâ”€â”€ formal_dress.jpg")
        print("    â””â”€â”€ casual_blouse.jpg")
    else:
        print("âœ… ëª¨ë“  ì„±ë³„ë³„ ì˜· ì´ë¯¸ì§€ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

    return True


def apply_outfit_synthesis(person_image_path: str, outfit_type: str) -> str:
    """
    IDM-VTON APIë¥¼ ì‚¬ìš©í•´ì„œ ì„±ë³„ì— ë§ëŠ” ì˜·ì„ í•©ì„±í•©ë‹ˆë‹¤.
    """
    global selected_gender

    try:
        # ì„±ë³„ë³„ ì˜· ê²½ë¡œ ì„¤ì •
        outfit_paths = {
            'male': {
                'formal': 'assets/male/formal_suit.jpg',
                'casual': 'assets/male/casual_shirt.jpg',
                'original': person_image_path
            },
            'female': {
                'formal': 'assets/female/formal_dress.jpg',
                'casual': 'assets/female/casual_blouse.jpg',
                'original': person_image_path
            }
        }

        if outfit_type == 'original':
            return person_image_path

        # í˜„ì¬ ì„±ë³„ì— ë§ëŠ” ì˜· ê²½ë¡œ ì„ íƒ
        current_gender = selected_gender or 'male'  # ê¸°ë³¸ê°’ male
        cloth_path = outfit_paths.get(current_gender, {}).get(outfit_type)

        if not cloth_path or not os.path.exists(cloth_path):
            print(f"âŒ {current_gender} {outfit_type} ì˜· ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {cloth_path}")
            return person_image_path

        print(f"ğŸ”„ {current_gender} {outfit_type} ìŠ¤íƒ€ì¼ í•©ì„± ì‹œì‘...")

        # client = Client("yisol/IDM-VTON", hf_token=os.getenv("HF_TOKEN"))

        NGROK_URL = "https://abcd-1234.ngrok-free.app"
        client = Client(NGROK_URL)

        result = client.predict(
            dict={
                "background": file(person_image_path),
                "layers": [],
                "composite": None
            },
            garm_img=file(cloth_path),
            garment_des=f"{current_gender} {outfit_type} clothing",  # ì„±ë³„ ì •ë³´ë„ í¬í•¨
            is_checked=True,
            is_checked_crop=False,
            denoise_steps=30,
            seed=42,
            api_name="/tryon"
        )

        result_path = person_image_path.replace('.jpg', f'_{current_gender}_{outfit_type}_tryon.jpg')

        if os.path.exists(result[0]):
            shutil.copy2(result[0], result_path)
            print(f"âœ… {current_gender} {outfit_type} í•©ì„± ì™„ë£Œ: {result_path}")
            return result_path
        else:
            print(f"âŒ í•©ì„± ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {result[0]}")
            return person_image_path

    except Exception as e:
        print(f"âŒ ì˜· í•©ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return person_image_path


app = Flask(__name__)
CORS(app)


load_dotenv()

# Flask-Mail ì„¤ì • (Gmail ì˜ˆì‹œ)
app.config['MAIL_SERVER'] = 'smtp.gmail.com'
app.config['MAIL_PORT'] = 587
app.config['MAIL_USE_TLS'] = True
app.config['MAIL_USERNAME'] = 'dbtmdwns990203@gmail.com'  # ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” êµ¬ê¸€ ì´ë©”ì¼ ì£¼ì†Œ
app.config['MAIL_PASSWORD'] = os.getenv("MAIL_PASSWORD")      # êµ¬ê¸€ ì•± ë¹„ë°€ë²ˆí˜¸
app.config['MAIL_DEFAULT_SENDER'] = ('ë‹ˆí†¤ë‚´í†¤', 'dbtmdwns990203@gmail.com') # ë³´ë‚´ëŠ” ì‚¬ëŒ ì´ë¦„/ì£¼ì†Œ

# Mail ê°ì²´ ì´ˆê¸°í™”
mail = Mail(app)


UPLOAD_FOLDER = 'uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)


def image_to_base64(path):
    with open(path, 'rb') as img_file:
        return base64.b64encode(img_file.read()).decode('utf-8')


latest_paths = []  # ì „ì—­ ë³€ìˆ˜



@app.route('/upload', methods=['POST'])
def upload_image():
    global latest_paths, selected_gender

    if 'file' not in request.files:
        return jsonify({'success': False, 'message': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({'success': False, 'message': 'íŒŒì¼ëª…ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤'}), 400

    # ì„±ë³„ ì •ë³´ ë°›ê¸°
    selected_gender = request.form.get('gender', 'male')  # ê¸°ë³¸ê°’ì€ 'male'
    print(f"ğŸ”¥ ì„ íƒëœ ì„±ë³„: {selected_gender}")

    save_path = os.path.join(UPLOAD_FOLDER, 'capture.jpg')
    file.save(save_path)
    print(f' ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {save_path}')

    # Create ID photo style image
    try:
        # 1. ë¨¼ì € ID ì‚¬ì§„ ìŠ¤íƒ€ì¼ë¡œ í¬ë¡­
        id_photo_path = create_id_photo(save_path)
        print(f' ID ì‚¬ì§„ ìŠ¤íƒ€ì¼ ë³€í™˜ ì™„ë£Œ: {id_photo_path}')

        # 2. ë°°ê²½ ì œê±° ë° í¼ìŠ¤ë„ ì»¬ëŸ¬ ë°°ê²½ ì ìš© (ë½€ìƒµ í¬í•¨)
        latest_paths = generate_recommended_images(id_photo_path)
        print(f' ë°°ê²½ ì œê±° ë° í¼ìŠ¤ë„ ë°°ê²½ ì ìš© ì™„ë£Œ: {latest_paths}')

    except Exception as e:
        print(f' ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}')
        return jsonify({'success': False, 'message': f'ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}'}), 500

    return jsonify({'success': True, 'message': 'ID ì‚¬ì§„ ë³€í™˜ ì™„ë£Œ'})


@app.route('/uploaded', methods=['GET'])
def get_uploaded_images():
    if latest_paths and all(os.path.exists(p) for p in latest_paths):
        base64_imgs = [image_to_base64(p) for p in latest_paths]

        # ê° ì´ë¯¸ì§€ì˜ ë½€ìƒµ ê°•ë„ ì •ë³´ë„ í•¨ê»˜ ì „ë‹¬
        image_info = []
        for idx, (path, img_b64) in enumerate(zip(latest_paths, base64_imgs)):
            enhancement_level = ["ì•½ê°„", "ì¤‘ê°„", "ê°•í•˜ê²Œ"][idx % 3]
            image_info.append({
                'image': img_b64,
                'enhancement': enhancement_level,
                'description': f'í¼ìŠ¤ë„ ì»¬ëŸ¬ ë°°ê²½ {idx + 1} - {enhancement_level} ë³´ì •'
            })

        return jsonify({
            'success': True,
            'images': base64_imgs,  # ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€
            'image_info': image_info,  # ìƒˆë¡œìš´ ìƒì„¸ ì •ë³´
            'color_category': latest_color_category
        })
    else:
        return jsonify({'success': False, 'message': 'ì—…ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤'}), 404


# ì¶”ê°€: ì‚¬ìš©ìê°€ íŠ¹ì • ë½€ìƒµ ê°•ë„ë¥¼ ì„ íƒí•  ìˆ˜ ìˆëŠ” ì—”ë“œí¬ì¸íŠ¸
@app.route('/enhance', methods=['POST'])
def enhance_image():
    """
    ì‚¬ìš©ìê°€ ì„ íƒí•œ ë½€ìƒµ ê°•ë„ë¡œ ì´ë¯¸ì§€ë¥¼ ì¬ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    data = request.json
    enhancement_level = data.get('level', 'medium')  # light, medium, strong
    image_index = data.get('index', 0)  # ì–´ë–¤ ì´ë¯¸ì§€ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í• ì§€

    if not latest_paths or image_index >= len(latest_paths):
        return jsonify({'success': False, 'message': 'ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400

    try:
        base_path = latest_paths[image_index]
        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
        original_path = base_path.split('_reco')[0] + '_idphoto.jpg'

        # ìƒˆë¡œìš´ ê°•ë„ë¡œ ì¬ì²˜ë¦¬
        foreground = remove_background_rembg(original_path)
        hsv_data = analyze_face(original_path)
        palette = get_recommended_backgrounds(hsv_data)

        # ì‚¬ìš©ìê°€ ì„ íƒí•œ ê°•ë„ë¡œë§Œ ì²˜ë¦¬
        bg = Image.new("RGBA", foreground.size, palette[0] + (255,))
        bg.paste(foreground, (0, 0), foreground)
        bg = bg.convert("RGB")
        enhanced_bg = apply_natural_enhancement(bg, enhancement_level)

        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_path = original_path.replace('.jpg', f'_custom_{enhancement_level}.jpg')
        enhanced_bg.save(temp_path)

        return jsonify({
            'success': True,
            'image': image_to_base64(temp_path),
            'enhancement': enhancement_level
        })

    except Exception as e:
        return jsonify({'success': False, 'message': f'ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}'}), 500


# ì „ì—­ ë³€ìˆ˜ì— ì˜ìƒë³„ ê²½ë¡œ ì €ì¥
outfit_preview_paths = {}  # {'original': 'path1', 'formal': 'path2', 'casual': 'path3'}


@app.route('/outfit-preview', methods=['POST'])
def get_outfit_preview():
    global latest_paths, outfit_preview_paths

    data = request.json
    selected_index = data.get('selected_index', 0)

    if not latest_paths or selected_index >= len(latest_paths):
        return jsonify({'success': False, 'message': 'ì„ íƒëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400

    try:
        selected_image_path = latest_paths[selected_index]
        outfit_types = ['original', 'formal', 'casual']
        previews = []

        # ì˜ìƒë³„ ê²½ë¡œ ì´ˆê¸°í™”
        outfit_preview_paths = {}

        for outfit_type in outfit_types:
            if outfit_type == 'original':
                result_path = selected_image_path
            else:
                result_path = apply_outfit_synthesis(selected_image_path, outfit_type)

            # ê²½ë¡œ ì €ì¥
            outfit_preview_paths[outfit_type] = result_path

            previews.append({
                'type': outfit_type,
                'image': image_to_base64(result_path),
                'label': {'original': 'ì›ë³¸', 'formal': 'ì •ì¥', 'casual': 'ìºì£¼ì–¼'}[outfit_type]
            })

        return jsonify({
            'success': True,
            'options': previews
        })

    except Exception as e:
        return jsonify({'success': False, 'message': f'ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì˜¤ë¥˜: {str(e)}'}), 500


@app.route('/generate-final', methods=['POST'])
def generate_final_image():
    global final_image_path, outfit_preview_paths

    data = request.json
    selected_outfit = data.get('selected_outfit', 'original')

    try:
        # ì´ë¯¸ ìƒì„±ëœ ì´ë¯¸ì§€ ê²½ë¡œ ì‚¬ìš© (ì¬í•©ì„±í•˜ì§€ ì•ŠìŒ)
        if selected_outfit in outfit_preview_paths:
            final_image_path = outfit_preview_paths[selected_outfit]
            print(f"âœ… ê¸°ì¡´ {selected_outfit} ì´ë¯¸ì§€ ì‚¬ìš©: {final_image_path}")
        else:
            return jsonify({'success': False, 'message': 'ì„ íƒëœ ì˜ìƒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}), 400

        return jsonify({
            'success': True,
            'message': 'ìµœì¢… ì´ë¯¸ì§€ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤'
        })

    except Exception as e:
        return jsonify({'success': False, 'message': f'ìµœì¢… ì´ë¯¸ì§€ ì„¤ì • ì˜¤ë¥˜: {str(e)}'}), 500

@app.route('/final-image', methods=['GET'])
def get_final_image():
    """
    ìƒì„±ëœ ìµœì¢… ì´ë¯¸ì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    global final_image_path

    if not final_image_path or not os.path.exists(final_image_path):
        return jsonify({'success': False, 'message': 'ìµœì¢… ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤'}), 400

    try:
        return jsonify({
            'success': True,
            'image': image_to_base64(final_image_path)
        })

    except Exception as e:
        return jsonify({'success': False, 'message': f'ì´ë¯¸ì§€ ë¡œë“œ ì˜¤ë¥˜: {str(e)}'}), 500

# ... (ê¸°ì¡´ /final-image ì—”ë“œí¬ì¸íŠ¸ ì•„ë˜ì— ì¶”ê°€)

@app.route('/send-email', methods=['POST'])
def send_final_image_email():
    """
    ìµœì¢… ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì´ë©”ì¼ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
    """
    global final_image_path

    data = request.json
    recipient_email = data.get('email')

    if not recipient_email:
        return jsonify({'success': False, 'message': 'ìˆ˜ì‹ ì ì´ë©”ì¼ ì£¼ì†Œê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

    if not final_image_path or not os.path.exists(final_image_path):
        return jsonify({'success': False, 'message': 'ì „ì†¡í•  ìµœì¢… ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 404

    try:
        # ì´ë©”ì¼ ë©”ì‹œì§€ ê°ì²´ ìƒì„±
        msg = Message(
            subject="[ID Photo Service] ìƒì„±ëœ ì¦ëª…ì‚¬ì§„ì…ë‹ˆë‹¤.",
            recipients=[recipient_email]
        )

        # ì´ë©”ì¼ ë³¸ë¬¸ ì„¤ì •
        msg.body = "ìš”ì²­í•˜ì‹  ì¦ëª…ì‚¬ì§„ì„ ì²¨ë¶€í•©ë‹ˆë‹¤. ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
        msg.html = "<p>ìš”ì²­í•˜ì‹  ì¦ëª…ì‚¬ì§„ì„ ì²¨ë¶€í•©ë‹ˆë‹¤.</p><p>ì´ìš©í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.</p>"

        # íŒŒì¼ ì²¨ë¶€
        with app.open_resource(final_image_path) as fp:
            # íŒŒì¼ëª…ë§Œ ì¶”ì¶œí•˜ì—¬ ì²¨ë¶€ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©
            file_name = os.path.basename(final_image_path)
            msg.attach(file_name, 'image/jpeg', fp.read())

        # ì´ë©”ì¼ ë°œì†¡
        mail.send(msg)

        return jsonify({
            'success': True,
            'message': f'{recipient_email}(ìœ¼)ë¡œ ì´ë¯¸ì§€ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì „ì†¡í–ˆìŠµë‹ˆë‹¤.'
        })

    except Exception as e:
        print(f"âŒ ì´ë©”ì¼ ì „ì†¡ ì˜¤ë¥˜: {str(e)}")
        return jsonify({'success': False, 'message': f'ì´ë©”ì¼ ì „ì†¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500



if __name__ == '__main__':
    # ì˜· ì´ë¯¸ì§€ ì—ì…‹ ì„¤ì •
    setup_outfit_assets()

    # gradio_client ì„¤ì¹˜ í™•ì¸
    try:
        from gradio_client import Client, file

        print("âœ… gradio_client ì¤€ë¹„ ì™„ë£Œ")
    except ImportError:
        print("âŒ gradio_clientê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”: pip install gradio_client")
        exit(1)

    app.run(host='0.0.0.0', port=5050, debug=True)